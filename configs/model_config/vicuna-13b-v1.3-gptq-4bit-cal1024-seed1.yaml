model: "hf/efficient-llm/vicuna-13b-v1.3-gptq-larger-caliset-vicuna_v1.1-temp@4bit_1024g_1seed"
type: CHAT
conv_template: "vicuna_v1.1"

model_loader: GPTQ
torch_dtype: null
quant_file: null  # For AutoAWQ
tokenizer_name: "lmsys/vicuna-13b-v1.3"
trust_remote_code: true
use_auth_token: true
disable_exllama: true